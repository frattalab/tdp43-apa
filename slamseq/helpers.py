#!/usr/bin/env python3

import pyranges as pr
import pandas as pd
import numpy as np
from typing import Literal

def get_terminal_regions(gr: pr.PyRanges,
                         feature_col = "Feature",
                         feature_key = "exon",
                         id_col = "transcript_id",
                         region_number_col = "exon_number",
                         number_type: Literal["stranded", "unstranded"] = "stranded",
                         which_region: str = "last",
                         filter_single = False,
                         ):
    '''Return the first/last interval in group of intervals

    Requires a column that provides a 1..n numbering of intervals within each group (can be generated by add_region_number). Extraction will always be with respect to strand (can handle strand-aware/non-strand aware ranking in region_number_col) 

    Parameters
    ----------
    gr : pr.PyRanges
        _description_
    feature_col : str, optional
        _description_, by default "Feature"
    feature_key : str, optional
        _description_, by default "exon"
    id_col : str, optional
        _description_, by default "transcript_id"
    region_number_col : str, optional
        _description_, by default "exon_number"
    number_type : str, optional
        _description_, by default ["stranded", "unstranded"]
    which_region : str, optional
        _description_, by default "last"
    filter_single : bool, optional
        _description_, by default False

    Returns
    -------
    _type_
        _description_
    '''


    assert number_type in ["stranded", "unstranded"]
    assert which_region in ["first", "last"]
    assert region_number_col in gr.columns.tolist()
    assert feature_col in gr.columns.tolist()
    assert id_col in gr.columns.tolist()

    # Make sure only 'exon' features are in the gr
    assert gr.as_df()[feature_col].drop_duplicates().tolist() == [feature_key], "only {} entries should be present in gr".format(feature_key)

    # Make sure region_number_col is int
    # assert gr.as_df()[region_number_col].dtype

    # Make sure gr is sorted by transcript_id & 'region number' (ascending order so 1..n)
    gr = gr.apply(lambda df: df.sort_values(by=[id_col, region_number_col], ascending=True))


    # Filter out single-exon transcripts
    if filter_single:
        print("Filtering for multi-exon transcripts...")
        print("Before: {}".format(len(set(gr.as_df()[id_col].tolist()))))

        # Setting to 'False' marks all duplicates as True (so keep these)
        gr = gr.subset(lambda df: df.duplicated(subset=[id_col], keep=False), nb_cpu=1)

        print("After: {}".format(len(set(gr.as_df()[id_col].tolist()))))


    if number_type == "stranded":
        # source = None means that 1 = first region of group regardless of strand
        # Pick last region entry by max region number for each transcript (id_col)
        # Pick first region entry by min region number for each transcript (id_col)

        # keep="last" sets last in ID to 'False' and all others true (negate to keep last only)
        # keep="first" sets first in ID to 'False'

        out_gr = gr.subset(lambda df: ~(df.duplicated(subset=[id_col], keep=which_region)),
                               nb_cpu=1
                              )


    else:
        # Numbering doesn't respect strand
        # Need to flip selecting first/last in group depending on strand
        # minus strand - pick min if Minus strand, max if plus strand

        if which_region == "first":
            # + strand - pick first in group, - strand - pick last in group

            out_gr = (gr.subset(lambda df:
                                    #1. plus strand & first in group/ID
                                    (df["Strand"] == "+") & ~(df.duplicated(subset=[id_col],
                                                                            keep="first")) |
                                    #2. minus strand & last in group/ID
                                    (df["Strand"] == "-") & ~(df.duplicated(subset=[id_col],
                                                                            keep="last")),
                                    nb_cpu=1)
                     )

        elif which_region == "last":
            # + strand - pick last in group/ID
            # - strand - pick first in group/ID
            out_gr = (gr.subset(lambda df:
                                    #1. plus strand & last in group/ID
                                    (df["Strand"] == "+") & ~(df.duplicated(subset=[id_col],
                                                                            keep="last")) |
                                    #2. minus strand & first in group/ID
                                    (df["Strand"] == "-") & ~(df.duplicated(subset=[id_col],
                                                                            keep="first")),
                                    nb_cpu=1)
                     )


    return out_gr


def _df_swap_coord(df: pd.DataFrame,
                   change: Literal['Start', 'End'],
                   replace_col: str
                   ):
    '''Swap one end of a coordinate range (i.e. either start or end) with a joined value

    Note: intended to be applied to internal df of pyranges 0.x/1.x dataframe i.e. all strand values are the same

    Adapted from pr.methods.new_position._new_position (to only swap a single coordinate)

    Parameters
    ----------
    df : pd.DataFrame
        _description_
    change : Literal[&#39;Start&#39;, &#39;End&#39;]
        _description_
    replace_col : str
        _description_
    old_out_suffix : str
        _description_

    Returns
    -------
    _type_
        _description_
    '''    ''''''
    
    # '''
    # Swap values in Start/End coordinates with a provided column
    # Adapted from pr.methods.new_position._new_position (to only swap a single coordinate)
    # '''
    assert isinstance(df, pd.DataFrame)
    assert change in ["Start", "End"]
    assert replace_col in df.columns

    # copy of original    
    to_change = df[change].copy()
    
    df.loc[:, change] = df[replace_col]
    df.loc[:, replace_col] = to_change

    return df


def _df_update_3p(df: pd.DataFrame, replace_suffix: str = "_b"):
    '''Update the 3' (strand-aware) coordinate of a joined internal PyRanges dataframe

    e.g. gr.apply(lambda df: _df_update_3p(df))

    Parameters
    ----------
    df : pd.DataFrame
        _description_
    '''

    assert "Strand" in df.columns
    assert (df["Strand"] == "+").all() or (df["Strand"] == "-").all()

    if (df["Strand"] == "+").all():
        # Update End col to update 3'end of interval
        out_col = "End" + replace_suffix
        assert out_col in df.columns
        out = _df_swap_coord(df, "End", out_col)
        

    else:
        # Update Start col to update 3'end of interval
        out_col = "Start" + replace_suffix
        assert out_col in df.columns
        out = _df_swap_coord(df, "Start", out_col)
    
    out_msk = out["End"] - out["Start"] <= 0
    print(f"Number of negative or zero-length updated intervals to be dropped - {sum(out_msk)}")
    out = out[~out_msk]

    return out


def _df_update_5p(df: pd.DataFrame, replace_suffix: str = "_b"):
    '''Update the 5' (strand-aware) coordinate of a joined internal PyRanges dataframe

    e.g. gr.apply(lambda df: _df_update_5p(df))

    Parameters
    ----------
    df : pd.DataFrame
        _description_
    '''

    assert "Strand" in df.columns
    assert (df["Strand"] == "+").all() or (df["Strand"] == "-").all()

    if (df["Strand"] == "+").all():
        # Update Start col to update 5'end of interval
        out_col = "Start" + replace_suffix
        assert out_col in df.columns
        out = _df_swap_coord(df, "Start", out_col)
        
    else:
        # Update End col to update 5'end of interval
        out_col = "End" + replace_suffix
        assert out_col in df.columns
        out = _df_swap_coord(df, "End", out_col)
    
    out_msk = (out["End"] - out["Start"]) <= 0
    print(f"Number of negative or zero-length updated intervals to be dropped - {sum(out_msk)}")
    out = out[~out_msk]

    return out


def _df_add_region_number(df: pd.DataFrame,
                         id_col: str,
                         sort_col: Literal["Start", "End"] = "Start",
                         number_type: Literal["stranded", "unstranded"] = "stranded",
                         zero_based: bool = False,
                         method: Literal["min", "first"] = "min") -> pd.Series:
    '''Return positional ranks of intervals belonging to a group 
    
    Numbering can be strand-aware (so most 5' is assigned smallest rank) or unstranded (so leftmost interval assigned smallest rank)
    By default the ranking is returned 1..n, but can also be returned with 0-based ranks/indexes (0..n-1)
    Function assumes dataframe conforms to pr.PyRanges internal dataframe structure (so should be used internally in a pr.assign (mainly by add_region_number))

    Parameters
    ----------
    df : pd.DataFrame
        _description_
    id_col : str
        _description_
    sort_col : str, optional
        interval column by which to rank. If stranded, then opposite to provided is used to get correct end for minus strand intervals, by default "Start"
    number_type : Literal[&quot;stranded&quot;, &quot;unstranded&quot;], optional
        _description_, by default "stranded"
    zero_based : bool, optional
        _description_, by default False
    method : Literal[&quot;min&quot;, &quot;first&quot;], optional
        method to resolve ties (see pd.rank), by default "min"

    Returns
    -------
    pd.Series
        _description_
    '''

    assert id_col in df.columns.tolist(), f"id_col - {id_col} - is not present in df for chr/strand pair {','.join([df.Chromosome.iloc[0], df.Strand.iloc[0]])}"

    if df.empty:
        return pd.Series()
    
    # 
    if number_type == "unstranded":
        # Start position smallest to largest = 5'-3' (i.e. use left-right order as provided by pr.sort())
        ranks = df.groupby(id_col)[sort_col].rank(method=method, ascending=True)

    # now strand-aware 5'-3' sort
    elif (df.Strand == "+").all():
        # since pr.sort() will put intervals in left-right order, can just use input column as is
        ranks = df.groupby(id_col)[sort_col].rank(method=method, ascending=True)

    else:
        # need to select opposite column to get strand-aware correct end
        # also need to flip the ranking order (i.e. positions in descending order = 5'-3')
        if sort_col == "Start":
            ranks = df.groupby(id_col)["End"].rank(method=method, ascending=False)

        else:
            # 3'end = leftmost i.e. start
            ranks = df.groupby(id_col)["Start"].rank(method=method, ascending=False)

    if zero_based:
        return ranks.subtract(1)
    
    else:
        return ranks


def add_region_number(gr: pr.PyRanges,
                      id_col: str = "transcript_id",
                      feature_key: str = "intron",
                      out_col: str = "intron_number",
                      feature_col: str = "Feature",
                      number_type: Literal["stranded", "unstranded"] = "stranded",
                      sort_col: Literal["Start", "End"] = "Start",
                      method: Literal["min", "first"] = "min",
                      nb_cpu: int = 1) -> pr.PyRanges:
    '''Add column to gr containing a 0-based region number column ordered left-most to right-most 0..n-1 by a group of features (e.g. transcript)


    Parameters
    ----------
    gr : pr.PyRanges
        _description_
    id_col : str, optional
        _description_, by default "transcript_id"
    feature_key : str, optional
        _description_, by default "intron"
    out_col : str, optional
        _description_, by default "intron_number"
    feature_col : str, optional
        _description_, by default "Feature"
    number_type : Literal[&quot;stranded&quot;, &quot;unstranded&quot;], optional
        _description_, by default "stranded"
    nb_cpu : int, optional
        _description_, by default 1

    Returns
    -------
    pr.PyRanges
        _description_
    '''

    # Make sure only 'feature_key' rows are in the gr
    assert gr.as_df()[feature_col].drop_duplicates().tolist() == [feature_key], f"only {feature_key} entries should be present in gr"

    # Make sure sorted by position first.
    gr = gr.sort()

    # Add in region number column left-most to right-most 1..n order for each group of intervals
    gr = gr.assign(out_col, lambda df: _df_add_region_number(df, id_col, sort_col=sort_col, number_type=number_type, method=method), nb_cpu=nb_cpu)

    return gr